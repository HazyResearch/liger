import numpy as np
from sklearn.metrics import precision_recall_fscore_support, accuracy_score
from sklearn.cluster import KMeans

def evaluate_models(FS_cluster_models, neg_balances_to_try, mode='dev', tune_by='f1'):    
    for i, FS_cluster in enumerate(FS_cluster_models):
        accs = []
        f1s = []
        for cb in neg_balances_to_try:
            data_temporal = FS_cluster.data_temporal
            triplet_model = FS_cluster.triplet_models[cb]
            preds_individual = triplet_model.predict_proba_marginalized(data_temporal[f'L_{mode}']).reshape(len(data_temporal[f'Y_{mode}']))
            _, _, f1, _ = precision_recall_fscore_support(data_temporal[f'Y_{mode}'], [
                1 if pred > 0.5 else -1 for pred in preds_individual
            ])
            acc = accuracy_score(data_temporal[f'Y_{mode}'], [
                1 if pred > 0.5 else -1 for pred in preds_individual
            ])
            if len(f1) > 1:
                accs.append(acc)
                f1s.append(f1[1])
            else:
                continue
        best_acc_idx = np.argmax(np.array(accs))
        best_f1_idx = np.argmax(np.array(f1s))
        if tune_by == 'f1':
            FS_cluster.set_best_cb(neg_balances_to_try[best_f1_idx])
        else:
            FS_cluster.set_best_cb(neg_balances_to_try[best_acc_idx])
        FS_cluster_models[i] = FS_cluster
    preds_all = []
    Y_arranged = []
    for i, FS_cluster in enumerate(FS_cluster_models):
        data_temporal = FS_cluster.data_temporal
        triplet_model = FS_cluster.triplet_models[FS_cluster.best_cb]
        preds_individual = triplet_model.predict_proba_marginalized(
                data_temporal[f'L_{mode}']).reshape(len(data_temporal[f'Y_{mode}']))
        preds_all.extend(preds_individual)
        Y_arranged.extend(data_temporal[f'Y_{mode}'])
    best_pre, best_rec, best_f1, best_support = precision_recall_fscore_support(Y_arranged, [
            1 if pred > 0.5 else -1 for pred in preds_all
        ])
    best_acc = accuracy_score(Y_arranged, [
        1 if pred > 0.5 else -1 for pred in preds_all
    ])
    return best_acc, best_pre[1], best_rec[1], best_f1[1], best_support[1], FS_cluster_models

def test_model(FS_cluster_models, best_cbs):
    preds_all = []
    Y_arranged = []
    for i, FS_cluster in enumerate(FS_cluster_models):
        data_temporal = FS_cluster.data_temporal
        triplet_model = FS_cluster.triplet_models[best_cbs[i]]
        preds_individual = triplet_model.predict_proba_marginalized(
            data_temporal[f'L_test']).reshape(len(data_temporal[f'Y_test']))
        preds_all.extend(preds_individual)
        Y_arranged.extend(data_temporal[f'Y_test'])

        pre, rec, f1, support = precision_recall_fscore_support(Y_arranged, [
            1 if pred > 0.5 else -1 for pred in preds_all
        ])
        acc = accuracy_score(Y_arranged, [
            1 if pred > 0.5 else -1 for pred in preds_all
        ])
    return acc, pre[1], rec[1], f1[1], support[1]

def evaluate_thresholds(thresholds, cluster_models, neg_balances_to_try,
                        L_train_expanded, L_dev_expanded, L_test_expanded,
                        Y_dev_raw, Y_test_raw, train_cluster_labels, dev_cluster_labels, test_cluster_labels,
                        evaluate_test=False, tune_test=False, best_cbs=None, tune_by='f1'):
    
    L_train_raw = L_train_expanded
    L_dev_raw = L_dev_expanded
    L_test_raw = L_test_expanded
    
    T = 1

    L_train = L_train_raw[:L_train_raw.shape[0] - (L_train_raw.shape[0] % T)]
    L_dev = L_dev_raw[:L_dev_raw.shape[0] - (L_dev_raw.shape[0] % T)]
    L_test = L_test_raw[:L_test_raw.shape[0] - (L_test_raw.shape[0] % T)]
    Y_dev = Y_dev_raw[:Y_dev_raw.shape[0] - (Y_dev_raw.shape[0] % T)]
    Y_test = Y_test_raw[:Y_test_raw.shape[0] - (Y_test_raw.shape[0] % T)]

    m_per_task = L_train.shape[1]

    m = T * m_per_task
    v = T
    
    for cluster_idx, FS_cluster in enumerate(cluster_models):
        points_in_cluster = np.argwhere(train_cluster_labels == cluster_idx)
        L_train_cluster = L_train[points_in_cluster]
            
        points_in_cluster = np.argwhere(dev_cluster_labels == cluster_idx)
        L_dev_cluster = L_dev[points_in_cluster]
        Y_dev_cluster = Y_dev[points_in_cluster]
        
        points_in_cluster = np.argwhere(test_cluster_labels == cluster_idx)
        L_test_cluster = L_test[points_in_cluster]
        Y_test_cluster = Y_test[points_in_cluster]
        
        n_frames_train = L_train_cluster.shape[0]
        n_frames_dev = L_dev_cluster.shape[0]
        n_frames_test = L_test_cluster.shape[0]
        n_frames_Y_dev = Y_dev_cluster.shape[0]
        n_frames_Y_test = Y_test_cluster.shape[0]
        n_seqs_train = n_frames_train // T
        n_seqs_dev = n_frames_dev // T
        n_seqs_test = n_frames_test // T
        n_seqs_Y_dev = n_frames_Y_dev // T
        n_seqs_Y_test = n_frames_Y_test // T
        
        data_temporal_cluster = {
            'L_train': np.reshape(L_train_cluster, (n_seqs_train, m)),
            'L_dev': np.reshape(L_dev_cluster, (n_seqs_dev, m)),
            'Y_dev': np.reshape(Y_dev_cluster, (n_seqs_Y_dev, v)),
            'L_test': np.reshape(L_test_cluster, (n_seqs_test, m)),
            'Y_test': np.reshape(Y_test_cluster, (n_seqs_Y_test, v))
        }
        FS_cluster.set_data_temporal(data_temporal_cluster)
        cluster_models[cluster_idx] = FS_cluster
        
    for i, FS_cluster in enumerate(cluster_models):
        for neg_balance in neg_balances_to_try:
            FS_cluster.fit(FS_cluster.data_temporal['L_train'], FS_cluster.data_temporal['Y_dev'], neg_balance)
        cluster_models[i] = FS_cluster
    acc, pre, rec, f1, support, FS_cluster_dev = evaluate_models(cluster_models, neg_balances_to_try, mode = 'dev', tune_by=tune_by)
    
    print('Dev Thresholds: {}'.format(thresholds))
    print('Dev Acc: {:.2%}\tPre: {:.2%}\tRec: {:.2%}\tF1: {:.2%}'.format(
        acc, pre, rec, f1))

    
    if tune_test:
        acc_test, pre_test, rec_test, f1_test, support_test, FS_cluster_test = evaluate_models(cluster_models, neg_balances_to_try, mode = 'test', tune_by=tune_by)
        print('Test Thresholds: {}'.format(thresholds))
        print('Test Acc: {:.2%}\tPre: {:.2%}\tRec: {:.2%}\tF1: {:.2%}'.format(
            acc_test, pre_test, rec_test, f1_test))

        return acc, pre, rec, f1, support, acc_test, pre_test, rec_test, f1_test, support_test, FS_cluster_dev, FS_cluster_test
    
    if evaluate_test:
        acc_test, pre_test, rec_test, f1_test, support_test = test_model(cluster_models,best_cbs,)
        print('Test Thresholds: {}'.format(thresholds))
        print('Test Acc: {:.2%}\tPre: {:.2%}\tRec: {:.2%}\tF1: {:.2%}'.format(
            acc_test, pre_test, rec_test, f1_test))
    
    return acc, pre, rec, f1, support

def cluster_embeddings(embeddings, n_clusters):
    kmeans = KMeans(n_clusters, random_state=0).fit(embeddings)
    embedding_groups = []
    for cluster_idx in range(n_clusters):
        embedding_idxs = np.argwhere(kmeans.labels_ == cluster_idx).flatten()
        cluster_embeddings = np.take(embeddings, embedding_idxs, axis=0)
        embedding_groups.append(cluster_embeddings)
    return kmeans, embedding_groups, kmeans.labels_